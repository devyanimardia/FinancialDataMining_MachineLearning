{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T20:12:30.862557Z",
     "start_time": "2023-04-13T20:12:29.041659Z"
    }
   },
   "outputs": [],
   "source": [
    "## NAME:Devyani Mardia\n",
    "## NETID: dm1633\n",
    "## Group members: David & Devyani\n",
    "\n",
    "################s\n",
    "## Code for HW 3 problem 2\n",
    "##\n",
    "## INSTRUCTIONS:\n",
    "## The following file uses ridge regression and logistic ridge regression to\n",
    "## predict the daily log-return of J.P. Morgan stocks.\n",
    "##\n",
    "## For part a, complete all parts labeled FILL IN.\n",
    "##\n",
    "################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "stocks = pd.read_csv(\"sp500_long.csv\")\n",
    "stocks = stocks[[\"BAC\", \"JPM\", \"GOOGL\", \"C\", \"GS\"]]\n",
    "\n",
    "ndays = stocks.shape[0]\n",
    "lag = 7\n",
    "\n",
    "num_comp = stocks.shape[1]\n",
    "\n",
    "stocks = np.array(stocks)\n",
    "Y = stocks[lag:ndays, 1]\n",
    "\n",
    "## X is a matrix of dimension   (ndays-lag) x (num_comp*lag+1)\n",
    "X = np.ones((ndays-lag, num_comp*lag+1))\n",
    "for ell in range(lag):\n",
    "    X[:, (num_comp*ell):(num_comp*(ell+1))] = stocks[ell:(ndays-lag+ell), :]\n",
    "\n",
    "ntrain = 700\n",
    "nvalid = 200\n",
    "\n",
    "train_ixs = np.arange(ntrain)\n",
    "valid_ixs = np.arange(ntrain, ntrain+nvalid)\n",
    "test_ixs = np.arange(ntrain+nvalid, len(Y))\n",
    "\n",
    "Ytrain = Y[train_ixs]\n",
    "Xtrain = X[train_ixs, :]\n",
    "\n",
    "Yvalid = Y[valid_ixs]\n",
    "Xvalid = X[valid_ixs, :]\n",
    "\n",
    "Ytest = Y[test_ixs]\n",
    "Xtest = X[test_ixs, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T20:13:10.082678Z",
     "start_time": "2023-04-13T20:13:10.017250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge test error: 0.008380 Baseline error: 0.008530\n"
     ]
    }
   ],
   "source": [
    "p = X.shape[1]\n",
    "\n",
    "lambdas = np.power(float(2), np.arange(-10, 12.5, 0.5))\n",
    "\n",
    "valid_errs = np.zeros(len(lambdas))\n",
    "\n",
    "for il in range(len(lambdas)):\n",
    "    betahat = np.linalg.inv(Xtrain.T @ Xtrain + (il * np.identity(36))) @ Xtrain.T @ Ytrain\n",
    "    valid_errs[il] = np.sum((Yvalid - Xvalid @ betahat)**2)\n",
    "\n",
    "lambda_star = lambdas[np.argmin(valid_errs)]\n",
    "\n",
    "Xlearn = np.vstack((Xtrain, Xvalid))\n",
    "Ylearn = np.concatenate((Ytrain, Yvalid))\n",
    "betahat = np.linalg.inv(Xtrain.T @ Xtrain + (lambda_star * np.identity(36))) @ Xtrain.T @ Ytrain\n",
    "## FILL IN: compute ridge regression estimate on combined training and validation data\n",
    "          ## with the optimal lambda chosen by validation\n",
    "\n",
    "test_err = np.sqrt(np.mean((Ytest - Xtest @ betahat)**2) )\n",
    "baseline_err = np.sqrt(np.mean((Ytest - np.mean(Ylearn))**2))\n",
    "\n",
    "print(f\"Ridge test error: {test_err:.6f} Baseline error: {baseline_err:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part b (free response)\n",
    "Why can't we use cross-validation for this prediction problem?\n",
    "Although we do perform some validation to select an optimal value for lambda, we do not – as we did in problem 1 – perform cross-validation. This is be-cause in this problem, we are working with time se-ries data, so sampling from our full dataset is not as straightforward. There are several additional factors that complicate cross validation given the nature of time series data, including things that could cause poor model behavior (e.g., points could be temporal-ly clumped or drawn in awkward orientations to cy-clic behavior in the data). There is also a potential theoretical “violation” when we apply straightfor-ward cross-validation to time series data, as we are allowing the model to peek into the future when generating a model; in other words, we could be us-ing future data to predict backwards, which is not the intention of a predictive model. There are some techniques that we could employ that consider the nature of time series data, such as sliding window cross validation or blocked cross validation.\n",
    "\n",
    "\n",
    "Part c (free response)\n",
    "Increase the value of the \\lag\" variable to 10, then to 15, 20, 25, and 30. What e ect does this have\n",
    "on the covariates Xi? What e ect does this have on both the in-sample and the test regression\n",
    "errors?\n",
    "\n",
    "Solution:\n",
    "\n",
    "For each increase in the lag variable, we are includ-ing an additional set of historical data in the covari-ate matrix we are using to train the model. Consider the case when our lag is 5. When we create a covari-ate matrix for our model, its first “observation” will be created using the first 5 observations of the origi-nal data, and it’s last observation will use the final 5 observations from the original data. We will have covariates with a lot of overlap, and even more as we increase the size of lag. In doing so, we use original observations to create a covariate matrix that be-haves like sliding a window of size lag down the da-taset, grabbing all the covariate information and the final response value for each time the window moves.\n",
    "This is helpful, since it allows us to capture historical data and help our model pay attention to trends in the data. However, we pay the price of quite quickly bloating our covariate size (and doing so without including any additional information, only repeating values), so we run an extreme risk of overfitting. We see this explicitly as w e vary the lag value in our stock prediction model, with our baseline error re-maining consistent as our test error grows, show in the figure."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
