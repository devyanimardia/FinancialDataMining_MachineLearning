{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=====1. Avg Accuracy of Shaq Free throw=====\n",
      "Average accuracy of Shaq's free throw: 52.27%\n",
      "\n",
      "\n",
      "=====2. Avg Accuracy of Shaq Free throw during home game=====\n",
      "Average accuracy of Shaq's free throw during a home game: 54.94%\n",
      "\n",
      "\n",
      "=====3. Avg Accuracy of Shaq Free throw when it is first shot=====\n",
      "Average accuracy of Shaq's free throw when the free throw is the first of the two free throws: 48.58%\n",
      "\n",
      "\n",
      "=====4. Chi-Square Test for association b/w a free throw and whether the game is home game or not=====\n",
      "Contingency Table for Referance: \n",
      " home_game    0    1\n",
      "shot_made          \n",
      "0          501  278\n",
      "1          514  339\n",
      "\n",
      "\n",
      "Chi-squared test statistic: 2.6779010107677776\n",
      "P-value: 0.1017497611642021\n",
      "\n",
      "\n",
      "=====5. Chi-Square Test for association b/w a free throw and whether it is first shot=====\n",
      "Contingency Table for Referance: \n",
      " first_shot    0    1\n",
      "shot_made           \n",
      "0           309  470\n",
      "1           409  444\n",
      "\n",
      "\n",
      "Chi-squared test statistic: 11.001452096828773\n",
      "P-value: 0.0009104053382288787\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "shaq = pd.read_csv(\"shaq.csv\")\n",
    "\n",
    "## Part (a)\n",
    "## COMPUTE each of the following:\n",
    "\n",
    "## 1. average accuracy of Shaq's free throw\n",
    "print(\"\\n\")\n",
    "print(\"=====1. Avg Accuracy of Shaq Free throw=====\")\n",
    "# select the rows where Shaq attempted a free throw\n",
    "free_throws = shaq[shaq[\"play\"].str.contains(\"free throw\")]\n",
    "\n",
    "# calculate the average accuracy of Shaq's free throw\n",
    "avg_accuracy = free_throws[\"shot_made\"].mean()\n",
    "\n",
    "print(\"Average accuracy of Shaq's free throw: {:.2f}%\".format(avg_accuracy * 100))\n",
    "\n",
    "## 2. average accuracy of Shaq's free throw during a home game\n",
    "print(\"\\n\")\n",
    "print(\"=====2. Avg Accuracy of Shaq Free throw during home game=====\")\n",
    "# select the rows where Shaq attempted a free throw and home game\n",
    "free_throws_hg = shaq[\n",
    "    (shaq[\"play\"].str.contains(\"free throw\")) & (shaq[\"home_game\"] == 1)\n",
    "]\n",
    "\n",
    "# calculate the average accuracy of Shaq's free throw\n",
    "avg_accuracy_hg = free_throws_hg[\"shot_made\"].mean()\n",
    "\n",
    "print(\n",
    "    \"Average accuracy of Shaq's free throw during a home game: {:.2f}%\".format(\n",
    "        avg_accuracy_hg * 100\n",
    "    )\n",
    ")\n",
    "\n",
    "## 3. average accuracy of Shaq's free throw when the free throw\n",
    "##    is the first of the two free throws.\n",
    "print(\"\\n\")\n",
    "print(\"=====3. Avg Accuracy of Shaq Free throw when it is first shot=====\")\n",
    "# select the rows where Shaq attempted a free throw and is the first shot\n",
    "free_throws_hg = shaq[\n",
    "    (shaq[\"play\"].str.contains(\"free throw\")) & (shaq[\"first_shot\"] == 1)\n",
    "]\n",
    "\n",
    "# calculate the average accuracy of Shaq's free throw\n",
    "avg_accuracy_fs = free_throws_hg[\"shot_made\"].mean()\n",
    "\n",
    "print(\n",
    "    \"Average accuracy of Shaq's free throw when the free throw is the first of the two free throws: {:.2f}%\".format(\n",
    "        avg_accuracy_fs * 100\n",
    "    )\n",
    ")\n",
    "## 4. perform a chi-squared test for association between \n",
    "##    a free throw result and whether the game is a home game or not.\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=====4. Chi-Square Test for association b/w a free throw and whether the game is home game or not=====\")\n",
    "\n",
    "# Create a contingency table of the counts of free throws made and missed for home and away games\n",
    "contingency_table = pd.crosstab(index=free_throws['shot_made'], columns=free_throws['home_game'])\n",
    "\n",
    "# Print the contingency table\n",
    "print(\"Contingency Table for Referance: \\n\", contingency_table)\n",
    "\n",
    "# Perform a chi-squared test for association between free throw result and home game\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the chi-squared test statistic and p-value\n",
    "print(\"\\n\")\n",
    "print(\"Chi-squared test statistic:\", chi2)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "## 5. perform a chi-squared test for association between\n",
    "##    a free throw result and whether the free throw is the first of the \n",
    "##    two free throws.\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=====5. Chi-Square Test for association b/w a free throw and whether it is first shot=====\")\n",
    "# Create a contingency table of the counts of free throws made and missed for first shot\n",
    "contingency_table = pd.crosstab(index=free_throws['shot_made'], columns=free_throws['first_shot'])\n",
    "\n",
    "# Print the contingency table\n",
    "print(\"Contingency Table for Referance: \\n\", contingency_table)\n",
    "\n",
    "# Perform a chi-squared test for association between free throw result and home game\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the chi-squared test statistic and p-value\n",
    "print(\"\\n\")\n",
    "print(\"Chi-squared test statistic:\", chi2)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "\n",
    "## end of part (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge error: 0.4695 +/- 0.0821    Baseline error: 0.4786 +/- 0.0763\n"
     ]
    }
   ],
   "source": [
    "features = [\"first_shot\", \"missed_first\", \"home_game\", \"cur_score\",\n",
    "\"opp_score\", \"cur_time\", \"score_ratio\", \"made_first\", \"losing\"]\n",
    "\n",
    "ntrial = 100\n",
    "err1 = np.zeros(ntrial)\n",
    "err2 = np.zeros(ntrial)\n",
    "\n",
    "for it in range(ntrial):\n",
    "    X = shaq[features].values\n",
    "    Y = shaq['shot_made']\n",
    "\n",
    "    n = X.shape[0]\n",
    "    ntrain = 1500\n",
    "    learn_ixs = np.random.choice(n, ntrain, replace=False)\n",
    "    test_ixs = [j for j in range(n) if j not in learn_ixs]\n",
    "    \n",
    "    X1 = X[learn_ixs, ]\n",
    "    Y1 = Y[learn_ixs]\n",
    "\n",
    "    X2 = X[test_ixs, ]\n",
    "    Y2 = Y[test_ixs]\n",
    "    \n",
    "    clf = LogisticRegressionCV(Cs=50, cv=5, penalty='l2', solver='lbfgs', max_iter=1000)## FILL IN: use LogisticRegressionCV function \n",
    "    clf.fit(X1, Y1)\n",
    "\n",
    "    Y2hat = clf.predict(X2)\n",
    "    myerr = np.mean( abs(Y2 - Y2hat) )\n",
    "\n",
    "    Y2baseline = np.ones(Y2.shape) ## FILL IN: compute the baseline prediction. The baseline predicts all 1 if \n",
    "                 ## the average of Y1 is at least 0.5, otherwise all 0.\n",
    "    if np.mean(Y1) < 0.5:\n",
    "        Y2baseline = np.zeros(Y2.shape)\n",
    "\n",
    "    baseline_err = np.mean( abs(Y2 - Y2baseline) )\n",
    "\n",
    "    err1[it] = myerr\n",
    "    err2[it] = baseline_err\n",
    "    \n",
    "print(\"Ridge error: %.4f +/- %.4f    Baseline error: %.4f +/- %.4f\" % (np.mean(err1), 2*np.std(err1), np.mean(err2), 2*np.std(err2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.Problem 3 Part (c) Choose the statement below which you agree with the most. Justify your answer in a sentence or two.\n",
    "1. The features are strongly predictive of Shaquille O'Neal's free throws.\n",
    "2. The features are weakly predictive of Shaquille O'Neal's free throws.\n",
    "3. There is no evidence that the features are at all predictive of Shaquille O'Neal's free throws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.525\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.522\n",
      "Method:                 Least Squares   F-statistic:                              183.0\n",
      "Date:                Sun, 12 Mar 2023   Prob (F-statistic):                   1.12e-233\n",
      "Time:                        22:33:37   Log-Likelihood:                         -1083.6\n",
      "No. Observations:                1500   AIC:                                      2185.\n",
      "Df Residuals:                    1491   BIC:                                      2233.\n",
      "Df Model:                           9                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.3527      0.058      6.119      0.000       0.240       0.466\n",
      "x2             0.4391      0.061      7.186      0.000       0.319       0.559\n",
      "x3             0.0364      0.027      1.355      0.176      -0.016       0.089\n",
      "x4            -0.0020      0.002     -0.879      0.379      -0.006       0.002\n",
      "x5             0.0024      0.002      1.086      0.278      -0.002       0.007\n",
      "x6             0.0001   7.02e-05      2.091      0.037     9.1e-06       0.000\n",
      "x7             0.0348      0.036      0.980      0.327      -0.035       0.104\n",
      "x8             0.4540      0.062      7.339      0.000       0.333       0.575\n",
      "x9             0.0343      0.050      0.693      0.488      -0.063       0.131\n",
      "==============================================================================\n",
      "Omnibus:                     5793.849   Durbin-Watson:                   1.906\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              229.625\n",
      "Skew:                          -0.093   Prob(JB):                     1.37e-50\n",
      "Kurtosis:                       1.092   Cond. No.                     3.45e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 3.45e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# convert boolean values to integers (0 or 1)\n",
    "X1 = X1.astype(int)\n",
    "\n",
    "# calculate the mean across columns\n",
    "mean = np.nanmean(X1, axis=0)\n",
    "\n",
    "# replace non-finite values with the mean\n",
    "X1 = np.nan_to_num(X1, nan=mean)\n",
    "\n",
    "model = sm.OLS(np.asarray(Y1), X1).fit()\n",
    "res = model.resid\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans. The features are weakly predictive of Shaquille O'Neal's free throws.\n",
    "\n",
    "Reason: baseline OLS model has 5/9 features higher p value and also the adjusted R squared is very low, which indicates that the features are weakly predictive of Shaquille O'Neal's free throws.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.Problem 3 Part (d) (free response)\n",
    "Give a two or three sentences answer to each of the following questions.\n",
    "\n",
    "1. Each row of the original dataset also contains the final score of the game in which the free throw was made. Why is it that we cannot use the final score of the game as a feature in making the prediction\n",
    "\n",
    "Ans. Final score of the game has no direct relation with the free throw as free throws come into picture when penalty shots are given to the team that a foul was committed against. Success of a free throw can be predicted using the free throw attempts, time remaining, 3 pointer records or shooting position of a player but total points is not very indicative of the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Why is it that, ideally, when holding out samples for the test set, we should choose a set of games and hold out ALL samples from those games?\n",
    "\n",
    "\n",
    "Ans. To ensure accurate evaluation of the model, it is best to select a set of games and exclude all of their samples when creating the test set. If we randomly choose test samples from the same games as the training samples, the model may learn information that is specific to the test set and lead to overly optimistic results. It also makes sure the the model is tested on completely new data that it has not been trained on, which gives us a better picture of the models performance and create a more generalized model which can be utilized across all the variations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
